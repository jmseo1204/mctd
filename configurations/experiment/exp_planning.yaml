defaults:
  - base_pytorch

training:
  lr: 5e-4
  precision: 16-mixed
  batch_size: 1024 # will use 16G GPU memory;
  max_steps: 200005 # 200k steps for full training
  max_epochs: -1 # train until max_steps

  checkpointing:
    every_n_train_steps: 2000 # save a checkpoint every 2000 steps

validation:
  precision: 32
  inference_mode: False
  batch_size: 2
  val_every_n_step: null # change to 1 when visualizing a trained checkpoint
  val_every_n_epoch: 5000 # change to null when visualizing a trained checkpoint
  limit_batch: 1
  seed: 1
